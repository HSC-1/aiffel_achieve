{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import copy\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다운로드에 매우 긴 시간이 소요됩니다. \n",
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'kitti',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tfds.show_examples(ds_train, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in TakeDataset:  \n",
    "    print('--Example--')\n",
    "    print(list(example.keys())) # example is `{'image': tf.Tensor, 'label': tf.Tensor}`\n",
    "    image = example[\"image\"]\n",
    "    filename = example[\"image/file_name\"].numpy().decode('utf-8')\n",
    "    objects = example[\"objects\"]\n",
    "\n",
    "print('--objects--')\n",
    "print(objects)\n",
    "img = Image.fromarray(image.numpy())\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_bbox(input_image, object_bbox):\n",
    "    input_image = copy.deepcopy(input_image)\n",
    "    draw = ImageDraw.Draw(input_image)\n",
    "\n",
    "    # 바운딩 박스 좌표(x_min, x_max, y_min, y_max) 구하기\n",
    "    width, height = img.size\n",
    "    print('width:', width, ' height:', height)\n",
    "    print(object_bbox.shape)\n",
    "    x_min = object_bbox[:,1] * width\n",
    "    x_max = object_bbox[:,3] * width\n",
    "    y_min = height - object_bbox[:,0] * height\n",
    "    y_max = height - object_bbox[:,2] * height\n",
    "\n",
    "    # 바운딩 박스 그리기\n",
    "    rects = np.stack([x_min, y_min, x_max, y_max], axis=1)\n",
    "    for _rect in rects:\n",
    "        print(_rect)\n",
    "        draw.rectangle(_rect, outline=(255,0,0), width=2)\n",
    "    print(input_image)\n",
    "    return input_image\n",
    "\n",
    "visualize_bbox(img, objects['bbox'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = os.getenv('HOME')+'/aiffel/object_detection/data'\n",
    "img_dir = os.getenv('HOME')+'/kitti_images'\n",
    "train_csv_path = data_dir + '/kitti_train.csv'\n",
    "\n",
    "# KITTI 데이터셋 ds_train을 파싱해서 dataframe으로 변환하는 parse_dataset 함수를 구현해 주세요.\n",
    "def parse_dataset(dataset, img_dir=\"kitti_images\", total=0):\n",
    "    if not os.path.exists(img_dir):\n",
    "        os.mkdir(img_dir)\n",
    "    # Dataset의 claas를 확인하여 class에 따른 index를 확인해둡니다.\n",
    "    # 저는 기존의 class를 차와 사람으로 나누었습니다.\n",
    "    type_class_map = {\n",
    "        0: \"car\",\n",
    "        1: \"car\",\n",
    "        2: \"car\",\n",
    "        3: \"person\",\n",
    "        4: \"person\",\n",
    "        5: \"person\",\n",
    "    }\n",
    "    # Keras retinanet을 학습하기 위한 dataset을 csv로 parsing하기 위해서 필요한 column을 가진 pandas.DataFrame을 생성합니다.\n",
    "    df = pd.DataFrame(columns=[\"img_path\", \"x1\", \"y1\", \"x2\", \"y2\", \"class_name\"])\n",
    "    for item in tqdm(dataset, total=total):\n",
    "        filename = item['image/file_name'].numpy().decode('utf-8')\n",
    "        img_path = os.path.join(img_dir, filename)\n",
    "\n",
    "        img = Image.fromarray(item['image'].numpy())\n",
    "        img.save(img_path)\n",
    "        object_bbox = item['objects']['bbox']\n",
    "        object_type = item['objects']['type'].numpy()\n",
    "        width, height = img.size\n",
    "\n",
    "        # tf.dataset의 bbox좌표가 0과 1사이로 normalize된 좌표이므로 이를 pixel좌표로 변환합니다.\n",
    "        x_min = object_bbox[:,1] * width\n",
    "        x_max = object_bbox[:,3] * width\n",
    "        y_min = height - object_bbox[:,2] * height\n",
    "        y_max = height - object_bbox[:,0] * height\n",
    "\n",
    "        # 한 이미지에 있는 여러 Object들을 한 줄씩 pandas.DataFrame에 append합니다.\n",
    "        rects = np.stack([x_min, y_min, x_max, y_max], axis=1).astype(np.int)\n",
    "        for i, _rect in enumerate(rects):\n",
    "            _type = object_type[i]\n",
    "            if _type not in type_class_map.keys():\n",
    "                continue\n",
    "            df = df.append({\n",
    "                \"img_path\": img_path,\n",
    "                \"x1\": _rect[0],\n",
    "                \"y1\": _rect[1],\n",
    "                \"x2\": _rect[2],\n",
    "                \"y2\": _rect[3],\n",
    "                \"class_name\": type_class_map[_type]\n",
    "            }, ignore_index=True)\n",
    "            break\n",
    "    return df\n",
    "\n",
    "df_train = parse_dataset(ds_train, img_dir, total=ds_info.splits['train'].num_examples)\n",
    "df_train.to_csv(train_csv_path, sep=',',index = False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv_path = data_dir + '/kitti_test.csv'\n",
    "\n",
    "df_test = parse_dataset(ds_test, img_dir, total=ds_info.splits['test'].num_examples)\n",
    "df_test.to_csv(test_csv_path, sep=',',index = False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_txt_path = data_dir + '/classes.txt'\n",
    "\n",
    "def save_class_format(path=\"./classes.txt\"):\n",
    "    class_type_map = {\n",
    "        \"car\" : 0,\n",
    "        \"person\": 1\n",
    "    }\n",
    "    with open(path, mode='w', encoding='utf-8') as f:\n",
    "        for k, v in class_type_map.items():\n",
    "            f.write(f\"{k},{v}\\n\")\n",
    "\n",
    "save_class_format(class_txt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RetinaNet 훈련이 시작됩니다!! 50epoch 훈련에 1시간 이상 소요될 수 있습니다. \n",
    "!python ~/aiffel/object_detection/keras-retinanet/keras_retinanet/bin/train.py --gpu 0 --multiprocessing --workers 4 --batch-size 2 --epochs 50 --steps 195 csv ~/aiffel/object_detection/data/kitti_train.csv ~/aiffel/object_detection/data/classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ~/aiffel/object_detection/keras-retinanet/keras_retinanet/bin/convert_model.py ./snapshots/resnet50_csv_10.h5 ./snapshots/resnet50_csv_50_infer.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "\n",
    "# import keras_retinanet\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.models import load_model\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "from keras_retinanet.utils.gpu import setup_gpu\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "gpu = '0'\n",
    "setup_gpu(gpu)\n",
    "\n",
    "model_path = os.path.join('.', 'snapshots', 'resnet50_csv_50_infer.h5')\n",
    "model = load_model(model_path, backbone_name='resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_path = 'data/test_set/go_1.png'\n",
    "\n",
    "# inference_on_image 함수를 구현해 주세요.\n",
    "def inference_on_image(model, img_path=\"./test_set/go_1.png\", visualize=True):\n",
    "    image = read_image_bgr(img_path)\n",
    "\n",
    "    # copy to draw on\n",
    "    draw = image.copy()\n",
    "    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    color_map = {\n",
    "        0: (0, 0, 255), # blue\n",
    "        1: (255, 0, 0) # red\n",
    "    }\n",
    "\n",
    "    # preprocess image for network\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "\n",
    "    # process image\n",
    "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "\n",
    "    # correct for image scale\n",
    "    boxes /= scale\n",
    "\n",
    "    # display images\n",
    "    if  visualize:\n",
    "        for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "            print(box)\n",
    "            if score < 0.5:\n",
    "                break\n",
    "            b = box.astype(int)\n",
    "            draw_box(draw, b, color=color_map[label])\n",
    "\n",
    "            caption = \"{:.3f}\".format(score)\n",
    "            draw_caption(draw, b, caption)\n",
    "\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(draw)\n",
    "        plt.show()            \n",
    "\n",
    "inference_on_image(model, img_path=img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'data/test_set/stop_1.png'\n",
    "inference_on_image(model, img_path=img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'data/test_set/stop_3.png'\n",
    "\n",
    "def self_drive_assist(img_path, size_limit=300):\n",
    "    image = read_image_bgr(img_path)\n",
    "\n",
    "    # copy to draw on\n",
    "    draw = image.copy()\n",
    "    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    color_map = {\n",
    "        0: (0, 0, 255), # blue\n",
    "        1: (255, 0, 0) # red\n",
    "    }\n",
    "\n",
    "    # preprocess image for network\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "\n",
    "    # process image\n",
    "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "\n",
    "    # correct for image scale\n",
    "    boxes /= scale\n",
    "    \n",
    "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "        # 만약 사람이 1명 이상이면 멈춘다.\n",
    "        if label == 1:\n",
    "            return \"Stop\"\n",
    "        \n",
    "        elif label == 0:\n",
    "            width = box[2] - box[0]\n",
    "            height = box[3] - box[1]\n",
    "            # 사람이 아닌 경우 width와 height 둘 중 하나가 300 이상이면 'Stop'\n",
    "            if width > 300 or height > 300:\n",
    "                return \"Stop\"\n",
    "        # 둘다 아니라면 그냥 간다.    \n",
    "        if score < 0.5:\n",
    "            return \"Go\"\n",
    "\n",
    "print(self_drive_assist(img_path)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def test_system(func):\n",
    "    work_dir = 'data/'\n",
    "    score = 0\n",
    "    test_set=[\n",
    "        (\"test_set/stop_1.png\", \"Stop\"),\n",
    "        (\"test_set/stop_2.png\", \"Stop\"),\n",
    "        (\"test_set/stop_3.png\", \"Stop\"),\n",
    "        (\"test_set/stop_4.png\", \"Stop\"),\n",
    "        (\"test_set/stop_5.png\", \"Stop\"),\n",
    "        (\"test_set/go_1.png\", \"Go\"),\n",
    "        (\"test_set/go_2.png\", \"Go\"),\n",
    "        (\"test_set/go_3.png\", \"Go\"),\n",
    "        (\"test_set/go_4.png\", \"Go\"),\n",
    "        (\"test_set/go_5.png\", \"Go\"),\n",
    "    ]\n",
    "\n",
    "    for image_file, answer in test_set:\n",
    "        image_path = work_dir + '/' + image_file\n",
    "        pred = func(image_path)\n",
    "        if pred == answer:\n",
    "            score += 10\n",
    "    print(f\"{score}점입니다.\")\n",
    "\n",
    "test_system(self_drive_assist)"
   ]
  }
 ]
}